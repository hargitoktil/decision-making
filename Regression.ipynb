{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression\n",
    "Kali ini kita akan membandingkan hasil regresi pada beberapa pada satu dataset. \n",
    "\n",
    "Data yang akan kita gunakan ada `insurance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('insurance_new.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encoding\n",
    "### Label Encoder\n",
    "Secara umum, semua data yang bersifat **categorical** harus diubah menjadi bentuk angka, dalam hal ini disebut dengan **encoding**. Caranya adalah sebagai berikut:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.sex = LabelEncoder().fit_transform(data.sex)\n",
    "\n",
    "data.smoker = LabelEncoder().fit_transform(data.smoker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoder\n",
    "One Hot Encoder bekerja dengan cara mengabil nilai pada satu kolom yang memiliki data categorical dan memisahkannya menjadi kolom terpisah. Setiap kolom akan diberikan nilai 0 apabila tidak ada dan 1 apabila ada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = data.iloc[:,5:6].values #ndarray\n",
    "\n",
    "## ohe for region\n",
    "ohe = OneHotEncoder() \n",
    "\n",
    "region = ohe.fit_transform(region).toarray()\n",
    "region = pd.DataFrame(region)\n",
    "region.columns = ['northeast', 'northwest', 'southeast', 'southwest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kita hapus kolom region\n",
    "del data['region']\n",
    "\n",
    "# kita gabungkan region ke dalam tabel data\n",
    "data = pd.concat([data, region], axis=1)\n",
    "\n",
    "# reorder kolom pada data\n",
    "columns = ['age', 'sex', 'bmi', 'children', 'northeast',\n",
    "       'northwest', 'southeast', 'southwest', 'smoker', 'charges']\n",
    "\n",
    "data = data[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#putting the data together:\n",
    "\n",
    "##take the numerical data from the original data\n",
    "X_num = data[['age', 'bmi', 'children']].copy()\n",
    "\n",
    "# Ambil data X saja\n",
    "X_final = data.drop(['charges'], 1)\n",
    "\n",
    "#define y as being the \"charges column\" from the original dataset\n",
    "y_final = data.charges\n",
    "\n",
    "#Test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembuatan Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression().fit(X_train,y_train)\n",
    "y_train_pred = lr.predict(X_train)\n",
    "y_test_pred = lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print('lr train score %.3f, lr test score: %.3f' % (\n",
    "lr.score(X_train,y_train),\n",
    "lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)  # Train the transformer object so it knows what means and variances to use\n",
    "X_transformed = scaler.transform(X_train)  # tran\n",
    "\n",
    "sgdreg = SGDRegressor(max_iter=1000,tol=1e-3,penalty=None,eta0=0.0005)\n",
    "sgdreg.fit(X_transformed, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgdreg = SGDRegressor(max_iter=1000,tol=1e-3,penalty=None,eta0=0.0005)\n",
    "sgdreg.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "y_train_pred = sgdreg.predict(X_train)\n",
    "y_test_pred = sgdreg.predict(X_test)\n",
    "\n",
    "#print score\n",
    "# print(\"lr.coef_: {}\".format(lr.coef_))\n",
    "# print(\"lr.intercept_: {}\".format(lr.intercept_))\n",
    "print('lr train score %.3f, lr test score: %.3f' % (\n",
    "sgdreg.score(X_train,y_train),\n",
    "sgdreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly = PolynomialFeatures (degree = 3)\n",
    "X_poly = poly.fit_transform(X_final)\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_poly,y_final, test_size = 0.33, random_state = 0)\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "#fit model\n",
    "poly_lr = LinearRegression().fit(X_train,y_train)\n",
    "\n",
    "y_train_pred = poly_lr.predict(X_train)\n",
    "y_test_pred = poly_lr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print('poly train score %.3f, poly test score: %.3f' % (\n",
    "poly_lr.score(X_train,y_train),\n",
    "poly_lr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr = SVR(kernel='linear', C = 300)\n",
    "\n",
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "#fit model\n",
    "svr = svr.fit(X_train,y_train.values.ravel())\n",
    "y_train_pred = svr.predict(X_train)\n",
    "y_test_pred = svr.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print('svr train score %.3f, svr test score: %.3f' % (\n",
    "svr.score(X_train,y_train),\n",
    "svr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(random_state=0)\n",
    "\n",
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "#fit model\n",
    "dt = dt.fit(X_train,y_train.values.ravel())\n",
    "y_train_pred = dt.predict(X_train)\n",
    "y_test_pred = dt.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print('dt train score %.3f, dt test score: %.3f' % (\n",
    "dt.score(X_train,y_train),\n",
    "dt.score(X_test, y_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestRegressor(n_estimators = 100,\n",
    "                              criterion = 'mse',\n",
    "                              random_state = 1,\n",
    "                              n_jobs = -1)\n",
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )\n",
    "\n",
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "\n",
    "#fit model\n",
    "forest.fit(X_train,y_train.values.ravel())\n",
    "y_train_pred = forest.predict(X_train)\n",
    "y_test_pred = forest.predict(X_test)\n",
    "\n",
    "#print score\n",
    "print('forest train score %.3f, forest test score: %.3f' % (\n",
    "forest.score(X_train,y_train),\n",
    "forest.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Function to print best hyperparamaters: \n",
    "def print_best_params(gd_model):\n",
    "    param_dict = gd_model.best_estimator_.get_params()\n",
    "    model_str = str(gd_model.estimator).split('(')[0]\n",
    "    print(\"\\n*** {} Best Parameters ***\".format(model_str))\n",
    "    for k in param_dict:\n",
    "        print(\"{}: {}\".format(k, param_dict[k]))\n",
    "    print()\n",
    "\n",
    "#test train split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.33, random_state = 0 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard scaler (fit transform on train, fit only on test)\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train.astype(np.float))\n",
    "X_test= sc.transform(X_test.astype(np.float))\n",
    "\n",
    "###Challenge 1: SVR parameter grid###\n",
    "# pakai default dari model itu, kalo sudah, baru kita tunning dengan hyper parameter tunning di model tersebut\n",
    "# baris param_grid_svr ini adalah contoh hyper paramater tunning\n",
    "param_grid_svr = dict(kernel=[ 'linear', 'poly'],\n",
    "                     degree=[2],\n",
    "                     C=[600, 700, 800, 900],\n",
    "                     epsilon=[0.0001, 0.00001, 0.000001])\n",
    "svr = GridSearchCV(SVR(), param_grid=param_grid_svr, cv=5, verbose=3)\n",
    "\n",
    "\n",
    "#fit model\n",
    "svr = svr.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "#print score\n",
    "print('\\n\\nsvr train score %.3f, svr test score: %.3f' % (\n",
    "svr.score(X_train,y_train),\n",
    "svr.score(X_test, y_test)))\n",
    "#print(svr.best_estimator_.get_params())\n",
    "\n",
    "print_best_params(svr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tol : tolerance\n",
    "# epsilon : error antara 0 sd 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Challenge 2:Decision Tree parameter grid###\n",
    "param_grid_dt = dict(min_samples_leaf=np.arange(9, 13, 1, int), \n",
    "                  max_depth = np.arange(4,7,1, int),\n",
    "                  min_impurity_decrease = [0, 1, 2],\n",
    "                 )\n",
    "\n",
    "dt = GridSearchCV(DecisionTreeRegressor(random_state=0), param_grid=param_grid_dt, cv=5,  verbose=3)\n",
    "\n",
    "\n",
    "\n",
    "#fit model\n",
    "dt = dt.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "\n",
    "#print score\n",
    "print('\\n\\ndt train score %.3f, dt test score: %.3f' % (\n",
    "dt.score(X_train,y_train),\n",
    "dt.score(X_test, y_test)))\n",
    "print_best_params(dt)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearch for RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Challenge 3:Random Forest parameter grid###\n",
    "param_grid_rf = dict(n_estimators=[20],\n",
    "                     max_depth=np.arange(1, 13, 2),\n",
    "                     min_samples_split=[2],\n",
    "                     min_samples_leaf= np.arange(1, 15, 2, int),\n",
    "                     bootstrap=[True, False],\n",
    "                     oob_score=[False, ])\n",
    "\n",
    "\n",
    "forest = GridSearchCV(RandomForestRegressor(random_state=0), param_grid=param_grid_rf, cv=5, verbose=3)\n",
    "\n",
    "#fit model\n",
    "forest.fit(X_train,y_train.values.ravel())\n",
    "\n",
    "\n",
    "#print score\n",
    "print('\\n\\nforest train score %.3f, forest test score: %.3f' % (\n",
    "forest.score(X_train,y_train),\n",
    "forest.score(X_test, y_test)))\n",
    "\n",
    "print_best_params(forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
