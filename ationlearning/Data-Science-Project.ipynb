{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science Project\n",
    "\n",
    "Anda diminta oleh pimpinan untuk membuat model prediksi klasifikasi atas `income` pada dataset **Adult Income**. Data ini diperoleh dari Machine Learning Repository UCI (https://archive.ics.uci.edu/ml/datasets/Adult).Target variabel (`income`) merupakan data categorical dengan 2 nilai `<=50k` dan `>50k`. \n",
    "\n",
    "Kemudian, Anda diminta untuk membandingkan model yang paling baik berdasarkan eksperimen yang Anda lakukan terhadap performa model.\n",
    "\n",
    "\n",
    "Langkah pertama adalah *import library*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dataset\n",
    "df_adult = pd.read_csv('adult.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apakah kita langsung dapat menggunakan data ini secara langsung?\n",
    "\n",
    "**Tentu Tidak !**\n",
    "\n",
    "Kali ini, kita akan memperkenalkan tahapan-tahapan yang akan Anda lakukan sebagai data scientist. Pada umumnya, tahapan yang bisa kita lakukan setidaknya terdiri dari beberapa tahapan berikut ini:\n",
    "\n",
    "1. Data Cleaning atau Preprocessing\n",
    "2. Explorasi Data\n",
    "3. Pengolahan Data\n",
    "4. Evaluasi\n",
    "\n",
    "Kali ini, kita akan melakukan tahapan 1 dan 2 terlebih dahulu.\n",
    "\n",
    "## 1. Data Cleaning / Data Preprocessing / Data Wrangling\n",
    "Tahap pertama adalah melakukan pembersihan data, tahapan ini penting karena sebagian besar pekerjaan Data Analis berkutat pada bagian ini dan tahap explorasi data. \n",
    "\n",
    "Di tahapan ini hal yang pertama kali dilakukan adalah melakukan *peek* data menggunakan fungsi `head`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari data tersebut di atas, terdapat 2 jenis data yaitu `int64` dan `object`. Tipe data `object` pada umumnya dapat berupa `String` yang juga pada umumnya, data yang bersifat categorical. Dari kolom tersebut di atas, dapat kita ketahui bahwa terdapat 48.842 jenis data.\n",
    "\n",
    "Hal yang paling penting di tahapan ini adalah:\n",
    "1. Cek atas data **NULL** <br>\n",
    "Data **NULL** tersebut bisa berbentuk tanda `-`, spasi, `NA` ataupun tanda lainnya. Strategi atas data **NULL** tersebut bisa kita lakukan *impute* atau pengisian, atau bisa dihilangkan seluruh baris (row) data tersebut. \n",
    "2. Cek atas data anomali (outlier) <br>\n",
    "Data anomali dapat dianalisis dengan metode *standard deviasi*. Normalnya, data yang bernilai bilangan riil bisa kita cari dan hilangkan agar tidak mempengaruhi performa dari model kita.\n",
    "\n",
    "Data anomali lainnya, bisa berupa **kesalahan ketik (typo)** ataupun nilai yang sebenarnya sama tetapi dituliskan berbeda.\n",
    "\n",
    "\n",
    "Oleh karena itu, kita bisa melakukan cek satu per satu untuk kolom berikut ini:\n",
    "\n",
    "1. `workclass`\n",
    "2. `education`\n",
    "3. `marital-status`\n",
    "4. `occupation`\n",
    "5. `relatiohship`\n",
    "6. `race`\n",
    "7. `gender`\n",
    "8. `native-country`\n",
    "9. `income`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'gender','native-country']\n",
    "for c in col:\n",
    "    print(c,':',df_adult[c].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Namun, kita hanya akan fokus terhadap 4 kolom saja yaitu `workclass`, `marital-status`, `country`, `occupation`, karena terlihat dari data categorical di atas, ada beberapa anomali salah satunya adalah nilai `?`.\n",
    "\n",
    "### Kolom workclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kolom workclass\n",
    "df_adult.workclass.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ada beberapa **anomali** pada value di dalam kolom `workclass` di antaranya, nilai `?` dan nilai `Self-emp-inc` yang sebenarnya sama dengan `Self-emp-not-inc`. \n",
    "\n",
    "Solusi: \n",
    "1. Lakukan perubahan pada nilai `?` menjadi `NA`, karena nilai `?` tidak dapat didefinisikan.\n",
    "2. Lakukan *merge* untuk nilai kategori pada `Self-emp-inc` dan `Self-emp-not-inc`.\n",
    "\n",
    "Lakukan cek nilai `NA` apakah ada di dalam dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek NA value di kolom workclass\n",
    "df_adult.workclass.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk mengubah nilai `?` menjadi `NA` ada **banyak** cara.\n",
    "\n",
    "\n",
    "Anda jangan terpaku pada salah satu cara, bahkan Anda bisa membuat cara baru."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang, kita memiliki data **NULL** !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cek NA value di kolom workclass\n",
    "df_adult.workclass.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Untuk melakukan merge atas nilai kategori `Self-emp-inc` dan `Self-emp-not-inc` menjadi `Self-employed` kita menggunakan metode yang sama seperti di atas. Namun, kali ini kita akan menggunakan cara yang sedikit berbeda, yaitu dengan membuat suatu fungsi baru yaitu `change_workclass`. Di sini, fungsi ini akan di-passing sebagai *argument* dalam method `apply`. Begitu juga dengan Government."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_selfemployed(x):\n",
    "    if x =='Self-emp-not-inc':\n",
    "        return 'Self-employed'\n",
    "    elif x =='Self-emp-inc':\n",
    "        return 'Self-employed'\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def change_government(x):\n",
    "    # SILAKAN ISI DI SINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mengganti kategori nilai untuk self employed\n",
    "df_adult.workclass = df_adult.workclass.apply(change_selfemployed)\n",
    "\n",
    "# mengganti kategori nilai untuk government\n",
    "\n",
    "\n",
    "# cek atas perubahan yang sudah kita lakukan\n",
    "df_adult.workclass.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolom Marital-status\n",
    "\n",
    "Kita mau mengubah status pernikahan menjadi 3 saja, `Married`, `Not-married`, dan `Never-married`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['marital-status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_married_status(x):\n",
    "    # ubah Divoroced, separated dan widowed menjadi 'Not-Married'\n",
    "    \n",
    "    # 'Never-married' tetap\n",
    "    \n",
    "    # yang lain menjadi 'Married'\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['marital-status'] = df_adult['marital-status'].apply(change_married_status)\n",
    "df_adult['marital-status'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolom Country\n",
    "\n",
    "Dari data `native-country` terlihat bahwa kita bisa menginginkan untuk melakukan **grouping** atas negara-negara asal tersebut ke dalam bentuk region yang sama, hal ini bertujuan untuk memberikan untuk *memberikan tambahan kekuatan* atas fitur `native-country`. Tentunya, hal ini merupakan diskresi dari masing-masing analis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita mengingkan adanya penggabungan antara negara dengan region yang sama. Maka, kita akan membaginya menjadi 5 bagian yaitu `north-america`, `asia`, `south-america`, `europe`, dan  `others`.\n",
    "\n",
    "Terdapat 2 cara yang bisa digunakan, cara paling cepat untuk menghemat memory adalah sebagai berikut:\n",
    "```python\n",
    "# buat dictionary\n",
    "dict_countries = {\n",
    "    'north_america' : [\"Canada\", \"Cuba\", \"Dominican-Republic\", \"El-Salvador\", \"Guatemala\", \"Haiti\", \"Honduras\", \n",
    "                         \"Jamaica\", \"Mexico\", \"Nicaragua\",\"Outlying-US(Guam-USVI-etc)\", \"Puerto-Rico\", \n",
    "                       \"Trinadad&Tobago\",\"United-States\"], \n",
    "    'asia' : [\"Cambodia\", \"China\", \"Hong\", \"India\", \"Iran\", \"Japan\", \"Laos\",\n",
    "              \"Philippines\", \"Taiwan\", \"Thailand\", \"Vietnam\"],\n",
    "    'south_america ' : [\"Columbia\", \"Ecuador\", \"Peru\"],\n",
    "    'europe' : [\"England\", \"France\", \"Germany\", \"Greece\", \"Holand-Netherlands\",\"Hungary\", \"Ireland\", \"Italy\",\n",
    "                    \"Poland\", \"Portugal\", \"Scotland\", \"Yugoslavia\"], \n",
    "    'others' : [\"South\", \"?\"]\n",
    "    }\n",
    "\n",
    "# buat fungsi \n",
    "def change_toregion(x):\n",
    "    for k,v in dict_countries.items():\n",
    "        if x in v:\n",
    "            return k\n",
    "        \n",
    "# apply perubahan pada semua data\n",
    "df_adult['native-country'] = df_adult['native-country'].apply(change_toregion)\n",
    "```\n",
    "\n",
    "Akan tetapi, kita akan menggunakan cara yang paling sederhana sebagai berikut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# buat list untuk setiap region\n",
    "north_america = [\"Canada\", \"Cuba\", \"Dominican-Republic\", \"El-Salvador\", \"Guatemala\", \"Haiti\", \"Honduras\", \n",
    " \"Jamaica\", \"Mexico\", \"Nicaragua\",\"Outlying-US(Guam-USVI-etc)\", \"Puerto-Rico\", \n",
    " \"Trinadad&Tobago\",\"United-States\"]\n",
    "asia = [\"Cambodia\", \"China\", \"Hong\", \"India\", \"Iran\", \"Japan\", \"Laos\",\n",
    "          \"Philippines\", \"Taiwan\", \"Thailand\", \"Vietnam\"]\n",
    "south_america = [\"Columbia\", \"Ecuador\", \"Peru\"]\n",
    "europe = [\"England\", \"France\", \"Germany\", \"Greece\", \"Holand-Netherlands\",\"Hungary\", \"Ireland\", \n",
    "          \"Italy\", \"Poland\", \"Portugal\", \"Scotland\", \"Yugoslavia\"]\n",
    "others = [\"South\", \"?\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply perubahan satu persatu \n",
    "# north_america\n",
    "\n",
    "# asia\n",
    "\n",
    "# south_america\n",
    "\n",
    "# europe\n",
    "\n",
    "# others\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perhatikan perubahannya\n",
    "df_adult['native-country'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kolom Occupation\n",
    "\n",
    "Kali ini kita hanya akan mengganti nilai `?` menjadi `NaN` dengan cara yang sama di atas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.occupation.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ubah ? menjadi NaN atau np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.occupation.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Exploration\n",
    "\n",
    "Tahap yang kedua ini sangat penting untuk dilakukan, umumnya kita melihat anomali yang terjadi di data dan melakukan tindakan yang diperlukan. Selanjutnya, tahapan berikut adalah melakukan visualisasi atas data yang ada.\n",
    "\n",
    "### Cari data anomali dan perbaiki\n",
    "Saat ini kita memiliki banyak data NULL berupa `NaN`, langkah yang bisa kita lakukan adalah pengisian *(impute)* atau penghapusan. Pilihan pertama dapat kita lakukan apabila dirasa penting, namun langkah kedualah yang akan kita lakukan untuk kesederhanaan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_adult[df_adult.occupation.isnull() == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_adult[df_adult.workclass.isnull() == True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_adult[df_adult.workclass.isnull() & df_adult.occupation.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult[df_adult.workclass.isnull() & df_adult.occupation.isnull()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat bahwa sebanyak 2.799 data terdapat 2 nilai `NaN` pada satu baris untuk kolom `occupation` dan `workclass`. Sedangkan, 2.809 hanya `occupation`.\n",
    "\n",
    "Karena kita ingin memprediksi besaran `income` maka, kita harus memiliki nilai ini. Oleh karena itu, kita akan menghilangkan semua data `NaN` ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hapus record yang memiliki nilai NaN pada attributnya\n",
    "df_adult = df_adult.dropna(how='any')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_adult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang, kita hanya memiliki 46.033 dataset setelah dibersihkan.\n",
    "\n",
    "### Cari Informasi Sebanyak-banyaknya dari data\n",
    "Tahapan ini dapat kita sebut dengan **Data Exploration**, salah satu tools yang kita gunakan adalah **visualisasi**. Teknik ini menjadi penting karena kita bisa mendapatkan informasi yang sebelumnya tidak bisa didapatkan hanya dari angka dan kata.\n",
    "\n",
    "Berikut ini kita tampilkan plot informasi pada setiap kolom terhadap income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "cols = 5\n",
    "rows = ceil(float(df_adult.shape[1]) / cols)\n",
    "# looping setiap kolom dan indeksnya\n",
    "for i, column in enumerate(df_adult.columns):\n",
    "    # urutan setiap subplot\n",
    "    ax = fig.add_subplot(rows, cols, i + 1)\n",
    "    # set judul chart\n",
    "    ax.set_title(column)\n",
    "    \n",
    "    if df_adult.dtypes[column] == np.object:\n",
    "        df_adult[column].value_counts().plot(kind=\"bar\", axes=ax)\n",
    "    else:\n",
    "        df_adult[column].hist(axes=ax)\n",
    "        plt.xticks(rotation=\"vertical\")\n",
    "        \n",
    "plt.subplots_adjust(hspace=0.7, wspace=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dapat dilihat dari data di atas, sebagian besar data ada di daerah `north_america`, dan sebagian besar income di bawah $50,000. Di samping itu, ras yang mendominasi adalah kulit putih dan gendernya pria.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.hist(df_adult.age, bins=100, normed=None, histtype='bar', stacked=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Berikutnya kita akan melakukan visualisasi dengan menggunakan *heatmap*, unutk mendapatkan korelasi antara variabel. Akan tetapi, sebelumnya kita akan melakukan `label encoding` pada target variabel dan `gender`, karena mereka adalah binary variabel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "salary_map={'<=50K': 1,'>50K':0}\n",
    "\n",
    "df_adult.income = df_adult['income'].map(salary_map).astype(int)\n",
    "\n",
    "df_adult['gender'] = df_adult['gender'].map({'Male':1,'Female':0}).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Di samping itu, terdapat data categorical yaitu `education` yang akan kita lakukan encoding, karena terlihat sangat mirip dengan `educational-num`. Untuk itu, kita coba lakukan `LabelEncoder` pada fitur ini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.education.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_adult' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-3fab85ae9e0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf_adult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meducation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_adult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meducation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df_adult' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Lakukan Label Encoder pada kolom education\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualisasi heatmap untuk mencari relasi variabel\n",
    "Proses ini penting, terutama untuk menghilangkan variabel yang sangat berkorelasi. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_correlation(df, size=15):\n",
    "    corr= df.corr()\n",
    "    fig, ax =plt.subplots(figsize=(size,size))\n",
    "    ax.matshow(corr)\n",
    "    plt.xticks(range(len(corr.columns)),corr.columns)\n",
    "    plt.yticks(range(len(corr.columns)),corr.columns)\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation(df_adult)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dari plot di atas terlihat dengan jelas bahwa `education` dan `educational-num` memang sangat berkaitan. Maka kita akan buang salah satu, tetapi `educational-num` ternyata memiliki properti **ordinal**, yaitu berurutan dengan makna dimana angka lebih besar, memiliki tingkat edukasi yang lebih tinggi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_adult['education']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Categorical Data\n",
    "Tahapan ini merupakan tahap akhir sebelum dilakukan data analisis.\n",
    "\n",
    "Seluruh fitur data yang bersifat categorical string, harus diubah menjadi angka. Terdapat 2 cara yang umum dilakukan, yaitu cara manual dengan mengaplikasikan fungsi `replace`, `map`, `apply` dan lainnya, serta cara lain yaitu menggunakan fungsi `LabelEncoder`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adult.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakukan Label Encoder pada \n",
    "# native-country\n",
    "\n",
    "# marital-status\n",
    "\n",
    "# relationship\n",
    "\n",
    "# race\n",
    "\n",
    "# occupation\n",
    "\n",
    "# workclass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Analisis\n",
    "Tahap ini merupakan tahapan pembentukan model dari dataset yang ada. \n",
    "Kali ini, Anda akan diminta untuk melakukan *model selection* yang artinya, melakukan pemilihan model yang paling bagus di antara model-model yang ada. \n",
    "\n",
    "Sebagaimana biasa, kita akan melakukan `train_test_split`. Kali ini, kita akan memisahkan antara data training dan data validasi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_adult.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# X merupakan dataset kecuali target variabel\n",
    "X = df.drop(['income'],axis=1)\n",
    "y = df.income\n",
    "\n",
    "# kita gunakan 70% data training\n",
    "split_size=0.3\n",
    "\n",
    "# Creation of Train and Test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=split_size,random_state=22)\n",
    "\n",
    "# Creation of Train and validation dataset\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan Pembuatan model dengan menggunakan `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "\n",
    "# buat objek model\n",
    "\n",
    "# fit model\n",
    "\n",
    "# panggil fungsi predict\n",
    "RF_prediction = ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buat evaluasi atas model `RandomForestClassifier`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('-'*40)\n",
    "print ('Accuracy score:')\n",
    "print (accuracy_score(y_test, RF_prediction))\n",
    "print ('-'*40)\n",
    "print ('Confusion Matrix:')\n",
    "print (confusion_matrix(y_test, RF_prediction))\n",
    "print ('-'*40)\n",
    "print ('Classification Matrix:')\n",
    "print (classification_report(y_test, RF_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lakukan Pembuatan model dengan menggunakan `SVC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "\n",
    "# buat objek model\n",
    "\n",
    "# fit model\n",
    "\n",
    "# panggil fungsi predict\n",
    "svc_prediction = ...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Buat evaluasi atas model `SVC`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('-'*40)\n",
    "print ('Accuracy score:')\n",
    "print (accuracy_score(y_test,svc_prediction))\n",
    "print ('-'*40)\n",
    "print ('Confusion Matrix:')\n",
    "print (confusion_matrix(y_test,svc_prediction))\n",
    "print ('-'*40)\n",
    "print ('Classification Matrix:')\n",
    "print (classification_report(y_test,svc_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
